{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerai is a hedge fund that crowdsources their market predictions.  They disseminate data that is anonymized so that the data scientists who are working on the forecasting are not even aware of the features and labels they are working with.  The prediction problem is reduced to a classification of predicting a gain or loss.\n",
    "\n",
    "In this chapter we will fit a variety models to Numerai data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by reading-in the data and organizing our features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499664</td>\n",
       "      <td>0.951271</td>\n",
       "      <td>0.127110</td>\n",
       "      <td>0.469706</td>\n",
       "      <td>0.188336</td>\n",
       "      <td>0.113830</td>\n",
       "      <td>0.917618</td>\n",
       "      <td>0.398412</td>\n",
       "      <td>0.418910</td>\n",
       "      <td>0.452983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137192</td>\n",
       "      <td>0.201437</td>\n",
       "      <td>0.507708</td>\n",
       "      <td>0.919475</td>\n",
       "      <td>0.978169</td>\n",
       "      <td>0.177080</td>\n",
       "      <td>0.101372</td>\n",
       "      <td>0.722138</td>\n",
       "      <td>0.832319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099515</td>\n",
       "      <td>0.682824</td>\n",
       "      <td>0.867939</td>\n",
       "      <td>0.943828</td>\n",
       "      <td>0.505526</td>\n",
       "      <td>0.886766</td>\n",
       "      <td>0.530862</td>\n",
       "      <td>0.531002</td>\n",
       "      <td>0.980002</td>\n",
       "      <td>0.941859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642640</td>\n",
       "      <td>0.533367</td>\n",
       "      <td>0.616879</td>\n",
       "      <td>0.697038</td>\n",
       "      <td>0.741461</td>\n",
       "      <td>0.086690</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.324666</td>\n",
       "      <td>0.552276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.671993</td>\n",
       "      <td>0.383901</td>\n",
       "      <td>0.533011</td>\n",
       "      <td>0.690863</td>\n",
       "      <td>0.176539</td>\n",
       "      <td>0.600196</td>\n",
       "      <td>0.381543</td>\n",
       "      <td>0.648849</td>\n",
       "      <td>0.831643</td>\n",
       "      <td>0.861746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520068</td>\n",
       "      <td>0.660924</td>\n",
       "      <td>0.538882</td>\n",
       "      <td>0.160117</td>\n",
       "      <td>0.765317</td>\n",
       "      <td>0.301772</td>\n",
       "      <td>0.352097</td>\n",
       "      <td>0.638205</td>\n",
       "      <td>0.383552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.578177</td>\n",
       "      <td>0.872357</td>\n",
       "      <td>0.679625</td>\n",
       "      <td>0.108961</td>\n",
       "      <td>0.945910</td>\n",
       "      <td>0.571062</td>\n",
       "      <td>0.891958</td>\n",
       "      <td>0.916592</td>\n",
       "      <td>0.141508</td>\n",
       "      <td>0.258504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037959</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.974103</td>\n",
       "      <td>0.187519</td>\n",
       "      <td>0.938254</td>\n",
       "      <td>0.560129</td>\n",
       "      <td>0.136483</td>\n",
       "      <td>0.284507</td>\n",
       "      <td>0.199446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.474311</td>\n",
       "      <td>0.639613</td>\n",
       "      <td>0.563562</td>\n",
       "      <td>0.169508</td>\n",
       "      <td>0.456858</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.357417</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.251147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>0.792327</td>\n",
       "      <td>0.711650</td>\n",
       "      <td>0.177080</td>\n",
       "      <td>0.247403</td>\n",
       "      <td>0.666598</td>\n",
       "      <td>0.755557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7   \n",
       "0  0.499664  0.951271  0.127110  0.469706  0.188336  0.113830  0.917618  \\\n",
       "1  0.099515  0.682824  0.867939  0.943828  0.505526  0.886766  0.530862   \n",
       "2  0.671993  0.383901  0.533011  0.690863  0.176539  0.600196  0.381543   \n",
       "3  0.578177  0.872357  0.679625  0.108961  0.945910  0.571062  0.891958   \n",
       "4  0.474311  0.639613  0.563562  0.169508  0.456858  0.580710  0.969811   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature13  feature14  feature15   \n",
       "0  0.398412  0.418910   0.452983  ...   0.137192   0.201437   0.507708  \\\n",
       "1  0.531002  0.980002   0.941859  ...   0.642640   0.533367   0.616879   \n",
       "2  0.648849  0.831643   0.861746  ...   0.520068   0.660924   0.538882   \n",
       "3  0.916592  0.141508   0.258504  ...   0.037959   0.604539   0.974103   \n",
       "4  0.357417  0.157594   0.251147  ...   0.038095   0.770200   0.697395   \n",
       "\n",
       "   feature16  feature17  feature18  feature19  feature20  feature21  target  \n",
       "0   0.919475   0.978169   0.177080   0.101372   0.722138   0.832319       0  \n",
       "1   0.697038   0.741461   0.086690   0.109533   0.324666   0.552276       1  \n",
       "2   0.160117   0.765317   0.301772   0.352097   0.638205   0.383552       0  \n",
       "3   0.187519   0.938254   0.560129   0.136483   0.284507   0.199446       1  \n",
       "4   0.792327   0.711650   0.177080   0.247403   0.666598   0.755557       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('../data/numerai_training_data.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_data.drop(columns='target').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_data['target'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data is Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about working with the Numerai data is that it is clean and normalized.  \n",
    "\n",
    "1. All the features are in the range of $[0, 1]$.\n",
    "1. All the features have a mean of 0.50 and a standard deviation of 0.28.\n",
    "1. The occurrence of labels is even at 50% gains and 50% losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0.511372\n",
       "feature2     0.492770\n",
       "feature3     0.492105\n",
       "feature4     0.499420\n",
       "feature5     0.502291\n",
       "feature6     0.493039\n",
       "feature7     0.480280\n",
       "feature8     0.494526\n",
       "feature9     0.492926\n",
       "feature10    0.489265\n",
       "feature11    0.495725\n",
       "feature12    0.510969\n",
       "feature13    0.489852\n",
       "feature14    0.509350\n",
       "feature15    0.487469\n",
       "feature16    0.509012\n",
       "feature17    0.488944\n",
       "feature18    0.484929\n",
       "feature19    0.491757\n",
       "feature20    0.509223\n",
       "feature21    0.498371\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0.282260\n",
       "feature2     0.287446\n",
       "feature3     0.282481\n",
       "feature4     0.284493\n",
       "feature5     0.289867\n",
       "feature6     0.287061\n",
       "feature7     0.287526\n",
       "feature8     0.288087\n",
       "feature9     0.293945\n",
       "feature10    0.287046\n",
       "feature11    0.290922\n",
       "feature12    0.285451\n",
       "feature13    0.291276\n",
       "feature14    0.290140\n",
       "feature15    0.286997\n",
       "feature16    0.289279\n",
       "feature17    0.284790\n",
       "feature18    0.290445\n",
       "feature19    0.283742\n",
       "feature20    0.291001\n",
       "feature21    0.289637\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a guess of increase for all assets would yield an accuracy of 50.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5051702657807309"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model that we will fit is a simple `LogisticRegression`.  We will use a 10-fold cross-validation accuracy as our goodness of fit metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mdl_logistic_regression = LogisticRegression(C=1.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 17.9 s, total: 39 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mdl_logistic_regression, df_X, df_y, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a mean accuracy of about 52% which is just slightly higher than guessing a gain for all assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219476744186047"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's fit a `RandomForestClassifier`.  We use a 5-fold cross-validation accuracy  rather than 10-fold because these models take time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "mdl_random_forest = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.4 s, sys: 0 ns, total: 44.4 s\n",
      "Wall time: 44.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.51858389, 0.51723422, 0.52450166, 0.51650748, 0.52460548])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(mdl_random_forest, df_X, df_y, cv=5, scoring='accuracy', verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to logistic regression we get a mean score of around 52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5202865448504983"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model that we will fit is a gradient boosted tree with the **xgboost** package.  We use 5-fold cross-validation to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "mdl_xgboost = XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.01, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51292566, 0.51775332, 0.51977782, 0.51629983, 0.515625  ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(mdl_xgboost, df_X, df_y, cv=5, scoring='accuracy', verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mean accuracy score is slightly lower at 51.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5164763289036545"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent sections we will try a variety of neural networks.  In order to check out-of-sample accuracy, let's first create a holdout set with `train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit our first neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 13:39:44.717146: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 13:39:44.941096: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 13:39:44.943020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 13:39:45.900127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set our random seeds to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=100):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's build up our dense feed-forward neural network.  We use 3 hidden layer with 16, 8, and 4 units, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16, input_dim=len(df_X.columns), activation='relu'))\n",
    "model.add(Dense(units=8, input_dim=len(df_X.columns), activation='relu'))\n",
    "model.add(Dense(units=4, input_dim=len(df_X.columns), activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 2.14 s, total: 32.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = model.fit(X_train, y_train, epochs=10, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our neural network model performs about the same as the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 813us/step - loss: 0.6916 - accuracy: 0.5192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6915713548660278, 0.5192068219184875]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we implement dropout regularization with our neural network.  We use a slightly different architecture with 2 hidden units of 64 and 32 units, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=len(df_X.columns), activation='relu'))\n",
    "model.add(Dropout(rate=0.1, seed=100))\n",
    "model.add(Dense(units=32, input_dim=len(df_X.columns), activation='relu'))\n",
    "model.add(Dropout(rate=0.1, seed=100))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.3 s, sys: 2.01 s, total: 34.3 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=10, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout reglarization doesn't seem to have much of an effect on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 898us/step - loss: 0.6916 - accuracy: 0.5192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6916125416755676, 0.5192068219184875]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we perform `l1` regularization on our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=len(df_X.columns), activation='relu', activity_regularizer=l1(0.0005)))\n",
    "model.add(Dense(units=32, input_dim=len(df_X.columns), activation='relu', activity_regularizer=l1(0.0005)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 1.75 s, total: 30.9 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=10, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, `l1` regularization doesn't seem improve performance that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 873us/step - loss: 0.6925 - accuracy: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6924766302108765, 0.5205045938491821]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Question:** Based on our results so far, which model would you select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Try some different neural architectures and see if you can improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
