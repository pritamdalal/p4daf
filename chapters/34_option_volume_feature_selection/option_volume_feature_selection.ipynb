{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option Volume: Feature Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we continue our prediction of option volume rank with the data that we wrangled in the previous chapter.  In particular, we will:\n",
    "\n",
    "1. Fit a linear regression to four features.\n",
    "1. Fit a lasso regression to our features to find the ones that have predictive power.\n",
    "1. Find the optimal `n_neighbors for` a `KNeighborsRegressor`.\n",
    "1. Run our backtest with the `KNeighborsRegressor` using the optimal `n_neighbors`.\n",
    "1. Find the optimal `max_depth` for a `RandomForestRegressor`.\n",
    "1. Run our backtest with the `RandomForestRegressor` using the optimal `max_depth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read-in our training data and backtest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/option_train_2017.csv')\n",
    "df_test = pd.read_csv('../data/option_test_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the following four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['iv_change_one_lag', 'scaled_return_one_lag', 'rank_one_lag', 'rank_change_one_lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run a linear regression with these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3654074977254579"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(df_features, np.ravel(df_label.values))\n",
    "linear_regression.score(df_features, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters and see if they make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iv_change_one_lag</td>\n",
       "      <td>0.010543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scaled_return_one_lag</td>\n",
       "      <td>-1.208765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rank_one_lag</td>\n",
       "      <td>0.680732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rank_change_one_lag</td>\n",
       "      <td>-0.274649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  coefficient\n",
       "0      iv_change_one_lag     0.010543\n",
       "1  scaled_return_one_lag    -1.208765\n",
       "2           rank_one_lag     0.680732\n",
       "3    rank_change_one_lag    -0.274649"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linear_regression_coefficients = \\\n",
    "    pd.DataFrame({\n",
    "        'feature':features,\n",
    "        'coefficient':linear_regression.coef_\n",
    "    })\n",
    "df_linear_regression_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "1. `iv_change` - a positive change in implied vol could be caused by supply/demand effects of increased option buying, which could carry through to the following day \n",
    "1. `scaled_return` - when a stock goes down, long positions in the stock get fearful (or greedy) and option buying increases\n",
    "1. `rank_one_lag` - if an underlying has high rank one day, it will likely have high rank the next day\n",
    "1. `rank_change_one_lag` - if an underlying has a jump in volume one day, it will usually revert back to previous levels the next day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is a linear regression technique that minimizes an objective function that involves residual-sum-of-squares and also the magnitude of the regression coefficients.\n",
    "\n",
    "In particular, it penalizes the objective for the collective magnitude of the regression coefficients.  This has the effect of making the coefficients of the non-predictive features equal to zero.\n",
    "\n",
    "Thus, lasso regression can be a way of weeding out non-predictive coefficients.\n",
    "\n",
    "Let's next fit a lasso regression to our four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3654059332222376"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "lasso = Lasso(alpha=0.10)\n",
    "lasso.fit(df_features, np.ravel(df_label.values))\n",
    "lasso.score(df_features, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the coefficients.  Notice that `iv_change_one_lag` has a value of 0, and thus it is not that predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iv_change_one_lag</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scaled_return_one_lag</td>\n",
       "      <td>-1.091635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rank_one_lag</td>\n",
       "      <td>0.680723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rank_change_one_lag</td>\n",
       "      <td>-0.274577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  coefficient\n",
       "0      iv_change_one_lag     0.000000\n",
       "1  scaled_return_one_lag    -1.091635\n",
       "2           rank_one_lag     0.680723\n",
       "3    rank_change_one_lag    -0.274577"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lasso_coefficients = \\\n",
    "    pd.DataFrame({\n",
    "        'feature':features,\n",
    "        'coefficient':lasso.coef_\n",
    "    })\n",
    "df_lasso_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alpha` hyperparameter controls how much the coefficient sizes are penalized.  We can use cross-validation to choose the optimal level of `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.3565912774339949\n",
      "0.2 0.35658669987577574\n",
      "0.3 0.35657893041868144\n",
      "0.4 0.35656800276703626\n",
      "0.5 0.35655390432426176\n",
      "0.6 0.35653663509035816\n",
      "0.7 0.35651619506532517\n",
      "0.8 0.3564925842491631\n",
      "0.9 0.3564673297611635\n",
      "1.0 0.3564481756197352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "alphas = np.linspace(0.1, 1, 10)\n",
    "for ix_alpha in alphas:\n",
    "   lasso = Lasso(alpha=ix_alpha)\n",
    "   cvs = cross_val_score(lasso, df_features, df_label, cv = 10)\n",
    "   print(np.round(ix_alpha, 2), cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the value of `alpha` doesn't seem to matter that much.  So we'll leave it as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Predictive Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove `iv_change_one_lag` as our lasso regression showed that it has low predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['scaled_return_one_lag', 'rank_one_lag', 'rank_change_one_lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the user defined functions we will need to use our top-$n$ metric in our backtest.  These functions were introduced in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_volume(n):\n",
    "    df_test = pd.read_csv(\"../data/option_test_2018.csv\")\n",
    "    df_top_n_volume = \\\n",
    "    (\n",
    "    df_test\n",
    "        .query('daily_volume_rank <= @n')\n",
    "        .groupby(['quotedate'])[['totalvol']].sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={'totalvol':'top_' + str(n) + '_volume'})\n",
    "    )\n",
    "    return(df_top_n_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top_n_ratio(n, trade_date, df_test, model=None, features=[]):\n",
    "    \n",
    "    # grabbing top-n volume for each day in backtest\n",
    "    df_top_n = top_n_volume(n)\n",
    "    \n",
    "    # grabbing feature observations for trade_date\n",
    "    df_prediction = df_test.query('quotedate == @trade_date').copy()\n",
    "    \n",
    "    # selecting features from df_X\n",
    "    df_X = df_prediction[features]\n",
    "    \n",
    "    # calculating model predictions\n",
    "    if model is not None:\n",
    "        df_prediction['prediction'] = model.predict(df_X) # predictions based on model\n",
    "    else:\n",
    "        df_prediction['prediction'] = df_prediction['rank_one_lag'] # simple-rule based predictor\n",
    "    \n",
    "    # sorting by predicted rank\n",
    "    df_prediction = df_prediction.sort_values(['prediction'])\n",
    "    # calculating predicted top-n volume\n",
    "    predicted_top_n_volume = df_prediction.head(n)['totalvol'].sum()\n",
    "    # querying for actual top-n volume\n",
    "    actual_top_n_volume = df_top_n.query('quotedate == @trade_date')['top_' + str(n) + '_volume'].values[0]\n",
    "    \n",
    "    # return the top-n-ratio\n",
    "    return(predicted_top_n_volume / actual_top_n_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(n, df_test, model=None, features=[]):\n",
    "    # all trade dates in backtest period\n",
    "    trade_dates = df_test['quotedate'].unique().tolist()\n",
    "    \n",
    "    # calculating all top-n ratios\n",
    "    top_n_ratios = []\n",
    "    for ix_trade_date in trade_dates:\n",
    "        top_n_ratios.append(calc_top_n_ratio(n, ix_trade_date, df_test, model, features))\n",
    "\n",
    "    # creating a dataframe of daily top-n ratios\n",
    "    df_daily = pd.DataFrame({\n",
    "        'trade_date':trade_dates,\n",
    "        'top_'+str(n)+'_volume': np.round(top_n_ratios, 3),\n",
    "    })\n",
    "\n",
    "    # calculating summary statsics of top-n ratios during backtest period\n",
    "    df_stats = pd.DataFrame({\n",
    "        'model':[str(model)],\n",
    "        'average':[np.mean(top_n_ratios).round(3)],\n",
    "        'std_dev':[np.std(top_n_ratios).round(3)],\n",
    "        'minimum':[np.min(top_n_ratios).round(3)],\n",
    "        'maximum':[np.max(top_n_ratios).round(3)],\n",
    "    })\n",
    "\n",
    "    return([df_daily, df_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll fit a `KNeighborsRegressor` to our training data and see how it performs during the backtest period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use a 10-fold cross validation (using $R^2$ as metric) to determine optimal value of `n_neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.36101494817841573\n",
      "200 0.36386843260646606\n",
      "300 0.3646175979349766\n",
      "400 0.36480461178161694\n",
      "500 0.3647867229860612\n",
      "600 0.3646215082035253\n",
      "700 0.3644970083233438\n",
      "800 0.36423480801137564\n",
      "900 0.36403894419896105\n",
      "1000 0.3638359335614717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "k = range(100, 1100, 100)\n",
    "for ix_k in k:\n",
    "    knn = KNeighborsRegressor(n_neighbors=ix_k)\n",
    "    cvs = cross_val_score(knn, df_features, df_label, cv = 10)\n",
    "    print(ix_k, cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't seem particularly sensitive to the value of `n_neighbors`, so let's just use 400 because it had the highest $R^2$ and the run-time seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's fit a `KNeighborsRegressor` to the entirety of our training data use `n_neighbors=400`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37700389902243137"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "knn = KNeighborsRegressor(n_neighbors=400)\n",
    "knn.fit(df_features, np.ravel(df_label.values))\n",
    "knn.score(df_features, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our fitted model to perform our backtest using top-25 ratio as our metric for success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    trade_date  top_10_volume\n",
       " 0   2018-01-05          0.831\n",
       " 1   2018-01-08          0.577\n",
       " 2   2018-01-09          0.659\n",
       " 3   2018-01-10          0.421\n",
       " 4   2018-01-11          0.532\n",
       " 5   2018-01-12          0.309\n",
       " 6   2018-01-16          0.599\n",
       " 7   2018-01-17          0.467\n",
       " 8   2018-01-18          0.398\n",
       " 9   2018-01-19          0.625\n",
       " 10  2018-01-22          0.708\n",
       " 11  2018-01-23          0.657\n",
       " 12  2018-01-24          0.496\n",
       " 13  2018-01-25          0.616\n",
       " 14  2018-01-26          0.763\n",
       " 15  2018-01-29          0.608\n",
       " 16  2018-01-30          0.471\n",
       " 17  2018-01-31          0.690,\n",
       "                                   model  average  std_dev  minimum  maximum\n",
       " 0  KNeighborsRegressor(n_neighbors=400)    0.579    0.131    0.309    0.831]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest(10, df_test, knn, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our KNN model actually performs worse than the simple rule-based predictor that we introduced in the previous chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll run our backtest using a `RandomForestRegressor`.  I've already run a cross-validation analysis that `n_estimators=10` has a good trade off of performance and run time.\n",
    "\n",
    "Let's find an optimal value of `max_depth` using a 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.21323542515349816\n",
      "2 0.28667668385608386\n",
      "3 0.32823705965447214\n",
      "4 0.350204904212642\n",
      "5 0.3604337950155293\n",
      "6 0.3643107573903573\n",
      "7 0.36517895534208716\n",
      "8 0.3638805625055838\n",
      "9 0.3627851611360925\n",
      "10 0.3582779076013644\n",
      "11 0.3539930070013009\n",
      "12 0.34701968731147276\n",
      "13 0.34101687956906235\n",
      "14 0.3326469340556921\n",
      "15 0.3248038486930812\n",
      "16 0.31443952345817633\n",
      "17 0.3059982711930008\n",
      "18 0.29436642171242966\n",
      "19 0.2866621073083838\n",
      "20 0.27945630028663293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "d = range(1, 21, 1)\n",
    "for ix_d in d:\n",
    "    random_forest = RandomForestRegressor(n_estimators=10, max_depth=ix_d)\n",
    "    cvs = cross_val_score(random_forest, df_features, np.ravel(df_label.values), cv = 10)\n",
    "    print(ix_d, cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our cross-validation analysis above, let's use `max_depth=7` to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.387368629069925"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "df_features = df_train[features]\n",
    "df_label = df_train[['daily_volume_rank']]\n",
    "random_forest = RandomForestRegressor(n_estimators = 10, max_depth=7)\n",
    "random_forest.fit(df_features, np.ravel(df_label.values))\n",
    "random_forest.score(df_features, df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run our backtest using the top-25 metric for our measure of success. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    trade_date  top_10_volume\n",
       " 0   2018-01-05          0.831\n",
       " 1   2018-01-08          0.577\n",
       " 2   2018-01-09          0.694\n",
       " 3   2018-01-10          0.421\n",
       " 4   2018-01-11          0.532\n",
       " 5   2018-01-12          0.338\n",
       " 6   2018-01-16          0.599\n",
       " 7   2018-01-17          0.511\n",
       " 8   2018-01-18          0.398\n",
       " 9   2018-01-19          0.625\n",
       " 10  2018-01-22          0.728\n",
       " 11  2018-01-23          0.571\n",
       " 12  2018-01-24          0.496\n",
       " 13  2018-01-25          0.661\n",
       " 14  2018-01-26          0.763\n",
       " 15  2018-01-29          0.576\n",
       " 16  2018-01-30          0.471\n",
       " 17  2018-01-31          0.690,\n",
       "                                                model  average  std_dev   \n",
       " 0  RandomForestRegressor(max_depth=7, n_estimator...    0.582    0.128  \\\n",
       " \n",
       "    minimum  maximum  \n",
       " 0    0.338    0.831  ]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest(10, df_test, random_forest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our random forest model also under performs relative our simple rule based model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
