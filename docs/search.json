[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python for Data Analysis in Finance",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#importing-packages",
    "href": "chapters/03_index_slice/index_slice.html#importing-packages",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.1 Importing Packages",
    "text": "3.1 Importing Packages\nLet’s begin by importing the packages that we will need.\n\nimport pandas as pd\nimport yfinance as yf\nyf.pdr_override()\nfrom pandas_datareader import data as pdr\npd.set_option('display.max_rows', 10)"
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#reading-in-data",
    "href": "chapters/03_index_slice/index_slice.html#reading-in-data",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.2 Reading-In Data",
    "text": "3.2 Reading-In Data\nNext, lets grab some data from Yahoo finance. In particular, we’ll grab SPY price data from July 2021.\n\ndf_spy = pdr.get_data_yahoo('SPY', start='2021-06-30', end='2021-07-31')\ndf_spy = df_spy.round(2)\ndf_spy.head()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n\n\n\n\n\nThe following code resets the index so that Date is a regular column; it also puts the column names into snake-case.\n\ndf_spy.reset_index(inplace=True)\ndf_spy.columns = df_spy.columns.str.lower().str.replace(' ', '_')\ndf_spy.head()\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n\n\n\n\n\nIt is often useful to look at the data type of each of the columns of a new data set. We can do so with the DataFrame.dtypes attribute.\n\ndf_spy.dtypes\n\ndate         datetime64[ns]\nopen                float64\nhigh                float64\nlow                 float64\nclose               float64\nadj_close           float64\nvolume                int64\ndtype: object"
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#row-slicing",
    "href": "chapters/03_index_slice/index_slice.html#row-slicing",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.3 Row Slicing",
    "text": "3.3 Row Slicing\nThe simplest way to slice a DataFrame is to use square brackets: []. The syntax df[i:j] will generate a DataFrame who’s first row is the ith row of df and who’s last row is the (j-1)th row of df. Let’s demonstrate this with a some examples:\nStarting from the 0th row, and ending with the 0th row:\n\ndf_spy[0:1]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n\n\n\n\n\nStarting with the 3rd row, and ending with the 6th row:\n\ndf_spy[3:7]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n5\n2021-07-08\n428.78\n431.73\n427.52\n430.92\n418.05\n97595200\n\n\n6\n2021-07-09\n432.53\n435.84\n430.71\n435.52\n422.51\n76238600\n\n\n\n\n\n\n\n\nCode Challenge: Retrieve the 15th, 16th, and 17th rows of df_spy.\n\n\nSolution\ndf_spy[15:18]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n15\n2021-07-22\n434.74\n435.72\n433.69\n435.46\n422.46\n47878500\n\n\n16\n2021-07-23\n437.52\n440.30\n436.79\n439.94\n426.80\n63766600\n\n\n17\n2021-07-26\n439.31\n441.03\n439.26\n441.02\n427.85\n43719200\n\n\n\n\n\n\n\n\nUsing the syntax df[:n] automatically starts the indexing at 0. For example, the following code retrieves all of df_spy (notice that len(df_spy) gives the number of rows of df_spy):\n\ndf_spy[:len(df_spy)]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17\n2021-07-26\n439.31\n441.03\n439.26\n441.02\n427.85\n43719200\n\n\n18\n2021-07-27\n439.91\n439.94\n435.99\n439.01\n425.90\n67397100\n\n\n19\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\n\n\n20\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\n\n\n21\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200\n\n\n\n\n22 rows × 7 columns\n\n\n\n\nCode Challenge: Retrieve the first five rows of df_spy.\n\n\nSolution\ndf_spy[:5]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n\n\n\n\n\n\nThere are a couple of row slicing tricks that involve negative numbers that are worth mentioning.\nThe syntax df[-n:] retrieves the last n rows of df. The following code retrieves the last five rows of df_spy.\n\ndf_spy[-5:]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n17\n2021-07-26\n439.31\n441.03\n439.26\n441.02\n427.85\n43719200\n\n\n18\n2021-07-27\n439.91\n439.94\n435.99\n439.01\n425.90\n67397100\n\n\n19\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\n\n\n20\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\n\n\n21\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200\n\n\n\n\n\n\n\nThe syntax df[:-n] retrieves all but the last n rows of df. The following code retrieves all but the last 10 rows of df_spy:\n\ndf_spy[:-10]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7\n2021-07-12\n435.43\n437.35\n434.97\n437.08\n424.03\n52889600\n\n\n8\n2021-07-13\n436.24\n437.84\n435.31\n435.59\n422.58\n52911300\n\n\n9\n2021-07-14\n437.40\n437.92\n434.91\n436.24\n423.21\n64130400\n\n\n10\n2021-07-15\n434.81\n435.53\n432.72\n434.75\n421.77\n55126400\n\n\n11\n2021-07-16\n436.01\n436.06\n430.92\n431.34\n418.46\n75874700\n\n\n\n\n12 rows × 7 columns\n\n\n\n\nCode Challenge: Retrieve the first row of df_spy with negative indexing.\n\n\nSolution\ndf_spy[:-(len(df_spy)-1)]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n\n\n\n\n\n\nCode Challenge: Use simple slicing to select the last three rows of a df_spy: 1) without explicitly using row numbers; 2) with explicitly using row numbers.\n\n\nSolution\ndf_spy[len(df_spy)-3:len(df_spy)]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n19\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\n\n\n20\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\n\n\n21\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200\n\n\n\n\n\n\n\n\n\nSolution\ndf_spy[-3:]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n19\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\n\n\n20\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\n\n\n21\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200"
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#dataframe-indexes",
    "href": "chapters/03_index_slice/index_slice.html#dataframe-indexes",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.4 DataFrame Indexes",
    "text": "3.4 DataFrame Indexes\nUnder the hood, a DataFrame has several indexes:\ncolumns - the set of column names is an (explicit) index.\nrow - whenever a DataFrame is created, there is an explicit row index that is created. If one isn’t specified, then a sequence of non-negative integers is used.\nimplicit - each row has an implicit row-number, and each column has an implicit column-number.\nLet’s take a look at the columns index of df_spy.\n\ndf_spy.columns\n\nIndex(['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume'], dtype='object')\n\n\n\ntype(df_spy.columns)\n\npandas.core.indexes.base.Index\n\n\nNext, let’s take a look at the explicit row index attribute of df_spy.\n\ndf_spy.index\n\nRangeIndex(start=0, stop=22, step=1)\n\n\n\ntype(df_spy.index)\n\npandas.core.indexes.range.RangeIndex\n\n\nSince we reset the index for df_spy, a RangeIndex object is used for the explicit row index. You can think of a RangeIndex object as a glorified set of consecutive integers.\nFor the most part, we won’t be too concerned with indexes. A lot of data analysis can be done without worrying about them. However, it’s good to be aware indexes exist becase they can come into play for more advanced topics, such as joining tables together; they also come up in Stack Overflow examples frequently.\nFor the purposes of this chapter, our interest in indexes comes from how they are related to two built-in DataFrame indexers: DataFrame.iloc and DataFrame.loc."
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#indexing-with-dataframe.iloc",
    "href": "chapters/03_index_slice/index_slice.html#indexing-with-dataframe.iloc",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.5 Indexing with DataFrame.iloc",
    "text": "3.5 Indexing with DataFrame.iloc\nThe indexer DataFrame.iloc can be used to access rows and columns using their implicit row and column numbers.\nHere is an example of iloc that retrieves the first two rows of df_spy.\n\ndf_spy.iloc[0:2,]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n\n\n\n\n\nNotice, that because we didn’t specify any column numbers, the code above retrieves all columns.\nThe following code grabs the first three row and the first three columns of df_spy.\n\ndf_spy.iloc[0:3, 0:3]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n\n\n1\n2021-07-01\n428.87\n430.60\n\n\n2\n2021-07-02\n431.67\n434.10\n\n\n\n\n\n\n\nWe can also supply .iloc with lists rather than ranges to specify custom sets of columns and rows:\n\nlst_row = [0, 2] # 0th and 2nd row\nlst_col = [0, 6] # date and adj_close columns\ndf_spy.iloc[lst_row, lst_col]\n\n\n\n\n\n\n\n\ndate\nvolume\n\n\n\n\n0\n2021-06-30\n64827900\n\n\n2\n2021-07-02\n57697700\n\n\n\n\n\n\n\nUsing lists as a means of indexing is sometimes referred to as fancy indexing.\n\nCode Challenge Use fancy indexing to grab the 14th, 0th, and 5th rows of df_spy - in that order.\n\n\nSolution\ndf_spy.iloc[[14, 0, 5]]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n14\n2021-07-21\n432.34\n434.70\n431.01\n434.55\n421.57\n64724400\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n5\n2021-07-08\n428.78\n431.73\n427.52\n430.92\n418.05\n97595200"
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#indexing-with-dataframe.loc",
    "href": "chapters/03_index_slice/index_slice.html#indexing-with-dataframe.loc",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.6 Indexing with DataFrame.loc",
    "text": "3.6 Indexing with DataFrame.loc\nRather than using the implicit row or column numbers, it is often more useful to access data by using the explicit row or column indices.\nLet’s use the DataFrame.set_index() method to set the date column as our new index. The dates will be a more interesting explicit index.\n\ndf_spy.set_index('date', inplace = True)\ndf_spy.head()\n\n\n\n\n\n\n\n\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n\n\n\n\n\nTo see the effect of the above code, we can have a look at the index of df_spy.\n\ndf_spy.index\n\nDatetimeIndex(['2021-06-30', '2021-07-01', '2021-07-02', '2021-07-06',\n               '2021-07-07', '2021-07-08', '2021-07-09', '2021-07-12',\n               '2021-07-13', '2021-07-14', '2021-07-15', '2021-07-16',\n               '2021-07-19', '2021-07-20', '2021-07-21', '2021-07-22',\n               '2021-07-23', '2021-07-26', '2021-07-27', '2021-07-28',\n               '2021-07-29', '2021-07-30'],\n              dtype='datetime64[ns]', name='date', freq=None)\n\n\nAnd notice that date is no longer column of df_spy.\n\ndf_spy.columns\n\nIndex(['open', 'high', 'low', 'close', 'adj_close', 'volume'], dtype='object')\n\n\nNow that we have successfully set the row index of df_spy to be the date, let’s see how we can use this index to access the data via .loc.\nHere is an example of how we can grab a slice of rows, associated with a date-range.\n\ndf_spy.loc['2021-07-23':'2021-07-31']\n\n\n\n\n\n\n\n\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2021-07-23\n437.52\n440.30\n436.79\n439.94\n426.80\n63766600\n\n\n2021-07-26\n439.31\n441.03\n439.26\n441.02\n427.85\n43719200\n\n\n2021-07-27\n439.91\n439.94\n435.99\n439.01\n425.90\n67397100\n\n\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\n\n\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\n\n\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200\n\n\n\n\n\n\n\nIf we want to select only the volume and adjusted columns for these dates, we would type the following:\n\ndf_spy.loc['2021-07-23':'2021-07-31', ['volume', 'adj_close']]\n\n\n\n\n\n\n\n\nvolume\nadj_close\n\n\ndate\n\n\n\n\n\n\n2021-07-23\n63766600\n426.80\n\n\n2021-07-26\n43719200\n427.85\n\n\n2021-07-27\n67397100\n425.90\n\n\n2021-07-28\n52472400\n425.73\n\n\n2021-07-29\n47435300\n427.49\n\n\n2021-07-30\n68951200\n425.42\n\n\n\n\n\n\n\n\nCode Challenge: Use .loc to grab the date, volume, and close columns from df_spy.\n\n\nSolution\ndf_spy.loc[:,['volume', 'close']]\n\n\n\n\n\n\n\n\n\nvolume\nclose\n\n\ndate\n\n\n\n\n\n\n2021-06-30\n64827900\n428.06\n\n\n2021-07-01\n53441000\n430.43\n\n\n2021-07-02\n57697700\n433.72\n\n\n2021-07-06\n68710400\n432.93\n\n\n2021-07-07\n63549500\n434.46\n\n\n...\n...\n...\n\n\n2021-07-26\n43719200\n441.02\n\n\n2021-07-27\n67397100\n439.01\n\n\n2021-07-28\n52472400\n438.83\n\n\n2021-07-29\n47435300\n440.65\n\n\n2021-07-30\n68951200\n438.51\n\n\n\n\n22 rows × 2 columns"
  },
  {
    "objectID": "chapters/03_index_slice/index_slice.html#related-reading",
    "href": "chapters/03_index_slice/index_slice.html#related-reading",
    "title": "3  DataFrame Indexing and Slicing",
    "section": "3.7 Related Reading",
    "text": "3.7 Related Reading\nPython Data Science Handbook - Section 2.7 - Fancy Indexing\nPython Data Science Handbook - Section 3.2 - Data Indexing and Selection"
  },
  {
    "objectID": "chapters/04_query/query.html#related-reading",
    "href": "chapters/04_query/query.html#related-reading",
    "title": "4  DataFrame Querying",
    "section": "4.7 Related Reading",
    "text": "4.7 Related Reading\nPython Data Science Handbook - Section 2.6 - Comparisons, Masks, and Boolean Logic\nPython Data Science Handbook - Section 2.7 - Fancy Indexing\nPython Data Science Handbook - Section 3.2 - Data Indexing and Selection\nPython Data Science Handbook - Section 3.12 - High Performance Pandas"
  },
  {
    "objectID": "chapters/04_query/query.html#importing-packages",
    "href": "chapters/04_query/query.html#importing-packages",
    "title": "4  DataFrame Querying",
    "section": "4.1 Importing Packages",
    "text": "4.1 Importing Packages\nLet’s first import the packages that we will need.\n\nimport pandas as pd\nimport yfinance as yf\nyf.pdr_override()\nfrom pandas_datareader import data as pdr\npd.set_option('display.max_rows', 10)"
  },
  {
    "objectID": "chapters/04_query/query.html#reading-in-data",
    "href": "chapters/04_query/query.html#reading-in-data",
    "title": "4  DataFrame Querying",
    "section": "4.2 Reading-In Data",
    "text": "4.2 Reading-In Data\nNext, let’s use pandas_datareader to read-in some SPY data from July 2021.\n\ndf_spy = pdr.get_data_yahoo('SPY', start='2021-06-30', end='2021-07-31')\ndf_spy = df_spy.round(2)\ndf_spy.head()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\n\n\n\n\n\n\n\nThe following code resets the index so that Date is a regular column, and then makes the all columns names snake-case.\n\ndf_spy.reset_index(inplace=True)\ndf_spy.columns = df_spy.columns.str.lower().str.replace(' ', '_')\ndf_spy.head()\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500"
  },
  {
    "objectID": "chapters/04_query/query.html#comparison-and-dataframe-columns",
    "href": "chapters/04_query/query.html#comparison-and-dataframe-columns",
    "title": "4  DataFrame Querying",
    "section": "4.3 Comparison and DataFrame Columns",
    "text": "4.3 Comparison and DataFrame Columns\nAs discussed in a previous chapter, a column of a DataFrame is a Series object, which is a souped up numpy.array (think vector or matrix).\nLet’s separate out the adjusted column of df_spy and assign it to a variable.\n\npd.options.display.max_rows = 6 # this modifies the printing of dataframes\nser_adjusted = df_spy['adj_close']\nser_adjusted\n\n0     415.28\n1     417.58\n2     420.77\n       ...  \n19    425.73\n20    427.49\n21    425.42\nName: adj_close, Length: 22, dtype: float64\n\n\nRecall that a pandas.Series is smart with respect to component-wise arithmetic operations, meaning it behaves like a vector from linear algebra. This means that arithmetic operations are broadcasted as you might expect.\nFor example, division by 100 is broadcasted component-wise.\n\nser_adjusted / 100\n\n0     4.1528\n1     4.1758\n2     4.2077\n       ...  \n19    4.2573\n20    4.2749\n21    4.2542\nName: adj_close, Length: 22, dtype: float64\n\n\nIt is a convenient fact that this broadcasting behavior also occurs with comparison, and produces a Series of booleans.\nThe following code checks which elements of ser_adjusted are greater than 425.\n\nser_test = (ser_adjusted &gt; 425)\nser_test\n\n0     False\n1     False\n2     False\n      ...  \n19     True\n20     True\n21     True\nName: adj_close, Length: 22, dtype: bool\n\n\nLet’s check that the resulting variable ser_test is a pandas.Series.\n\ntype(ser_test)\n\npandas.core.series.Series\n\n\nAnd finally let’s observe the .values elements of ser_test.\n\nprint(ser_test.values)\n\n[False False False False False False False False False False False False\n False False False False  True  True  True  True  True  True]\n\n\nA few observation about what just happened:\n\nWhen we compare a Series of numerical values (ser_adjusted) to a single number (425), we get back a Series of booleans (ser_test).\nWe have that ser_test[i] = (ser_adjusted[i] &gt; 425).\nSo the comparison operation was broadcasted as advertised.\n\nThis is easy to see by appending ser_test to df_spy and then reprinting.\n\npd.options.display.max_rows = 25\ndf_spy['test'] = ser_test\ndf_spy\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\ntest\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\nFalse\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\nFalse\n\n\n2\n2021-07-02\n431.67\n434.10\n430.52\n433.72\n420.77\n57697700\nFalse\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\nFalse\n\n\n4\n2021-07-07\n433.66\n434.76\n431.51\n434.46\n421.49\n63549500\nFalse\n\n\n5\n2021-07-08\n428.78\n431.73\n427.52\n430.92\n418.05\n97595200\nFalse\n\n\n6\n2021-07-09\n432.53\n435.84\n430.71\n435.52\n422.51\n76238600\nFalse\n\n\n7\n2021-07-12\n435.43\n437.35\n434.97\n437.08\n424.03\n52889600\nFalse\n\n\n8\n2021-07-13\n436.24\n437.84\n435.31\n435.59\n422.58\n52911300\nFalse\n\n\n9\n2021-07-14\n437.40\n437.92\n434.91\n436.24\n423.21\n64130400\nFalse\n\n\n10\n2021-07-15\n434.81\n435.53\n432.72\n434.75\n421.77\n55126400\nFalse\n\n\n11\n2021-07-16\n436.01\n436.06\n430.92\n431.34\n418.46\n75874700\nFalse\n\n\n12\n2021-07-19\n426.19\n431.41\n421.97\n424.97\n412.28\n147987000\nFalse\n\n\n13\n2021-07-20\n425.68\n432.42\n424.83\n431.06\n418.19\n99608200\nFalse\n\n\n14\n2021-07-21\n432.34\n434.70\n431.01\n434.55\n421.57\n64724400\nFalse\n\n\n15\n2021-07-22\n434.74\n435.72\n433.69\n435.46\n422.46\n47878500\nFalse\n\n\n16\n2021-07-23\n437.52\n440.30\n436.79\n439.94\n426.80\n63766600\nTrue\n\n\n17\n2021-07-26\n439.31\n441.03\n439.26\n441.02\n427.85\n43719200\nTrue\n\n\n18\n2021-07-27\n439.91\n439.94\n435.99\n439.01\n425.90\n67397100\nTrue\n\n\n19\n2021-07-28\n439.68\n440.30\n437.31\n438.83\n425.73\n52472400\nTrue\n\n\n20\n2021-07-29\n439.82\n441.80\n439.81\n440.65\n427.49\n47435300\nTrue\n\n\n21\n2021-07-30\n437.91\n440.06\n437.77\n438.51\n425.42\n68951200\nTrue\n\n\n\n\n\n\n\nAs we will see in the next two sections, the broadcasting of comparison can be used to query subsets of rows of a DataFrame."
  },
  {
    "objectID": "chapters/04_query/query.html#dataframe-masking",
    "href": "chapters/04_query/query.html#dataframe-masking",
    "title": "4  DataFrame Querying",
    "section": "4.4 DataFrame Masking",
    "text": "4.4 DataFrame Masking\nFrom the code below we know that df_spy has 22 rows.\n\ndf_spy.shape\n\n(22, 8)\n\n\nThe following code creates a list consisting of 22 booleans, all of them False.\n\nlst_bool = [False] * 22\nlst_bool\n\n[False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False]\n\n\nNow, let’s see what happens when we feed this list of False booleans into df_spy using square brackets.\n\ndf_spy[lst_bool]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\ntest\n\n\n\n\n\n\n\n\n\n\nCode Challenge: Verify that df_spy[lst_bool] is an empty DataFrame.\n\n\nSolution\ntype(df_spy[lst_bool])\n\n\npandas.core.frame.DataFrame\n\n\n\n\nSolution\ndf_spy[lst_bool].shape\n\n\n(0, 8)\n\n\n\nNext, let’s modify lst_bool slightly by changing the 0th entry to True. Then lets feed lst_bool into df_spy again.\n\nlst_bool[0] = True\ndf_spy[lst_bool]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\ntest\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\nFalse\n\n\n\n\n\n\n\nSo what happened? Notice that df_spy[lst_bool] returns a DataFrame consisting only of the 0th row of df_spy.\nLet’s modify lst_bool once again, by setting the 1st entry of df_spy to True, and then once again feed it into df_spy.\n\nlst_bool[1] = True\ndf_spy[lst_bool]\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\ntest\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\nFalse\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\nFalse\n\n\n\n\n\n\n\nPunchline: What is returned by the code df_spy[lst_bool] will be a DataFrame consisting of all the rows corresponding to the True entries of lst_bool.\nThis is called DataFrame masking.\n\nCode Challenge: Modify lst_bool and then use DataFrame masking to grab the 0th, 1st and, 3rd rows of df_spy.\n\n\nSolution\nlst_bool[3] = True\ndf_spy[lst_bool]\n\n\n\n\n\n\n\n\n\ndate\nopen\nhigh\nlow\nclose\nadj_close\nvolume\ntest\n\n\n\n\n0\n2021-06-30\n427.21\n428.78\n427.18\n428.06\n415.28\n64827900\nFalse\n\n\n1\n2021-07-01\n428.87\n430.60\n428.80\n430.43\n417.58\n53441000\nFalse\n\n\n3\n2021-07-06\n433.78\n434.01\n430.01\n432.93\n420.00\n68710400\nFalse"
  },
  {
    "objectID": "chapters/04_query/query.html#querying-with-dataframe-masking",
    "href": "chapters/04_query/query.html#querying-with-dataframe-masking",
    "title": "4  DataFrame Querying",
    "section": "4.5 Querying with DataFrame Masking",
    "text": "4.5 Querying with DataFrame Masking\nWe often want to query a DataFrame based on some kind of comparison involving its column values.\nWe can achieve this kind of querying by combining the broadcasting of comparison over DataFrame columns with DataFrame masking.\nIn order to consider concrete examples, let’s read-in some data.\nThe following code reads in a data set consisting of end-of-day prices for four different ETFs (SPY, IWM, QQQ, DIA), during the month of July 2021.\n\npd.options.display.max_rows = 25\ndf_etf = pdr.get_data_yahoo(['SPY', 'QQQ', 'IWM', 'DIA'], start='2021-06-30', end='2021-07-31')\ndf_etf = df_etf.round(2)\ndf_etf.head()\n\n[*********************100%***********************]  4 of 4 completed\n\n\n\n\n\n\n\n\n\nAdj Close\nClose\nHigh\n...\nLow\nOpen\nVolume\n\n\n\nDIA\nIWM\nQQQ\nSPY\nDIA\nIWM\nQQQ\nSPY\nDIA\nIWM\n...\nQQQ\nSPY\nDIA\nIWM\nQQQ\nSPY\nDIA\nIWM\nQQQ\nSPY\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021-06-30\n331.30\n223.29\n349.98\n415.28\n344.95\n229.37\n354.43\n428.06\n345.51\n230.32\n...\n353.83\n427.18\n342.38\n228.65\n354.83\n427.21\n3778900\n26039000\n32724000\n64827900\n\n\n2021-07-01\n332.66\n225.26\n350.11\n417.58\n346.36\n231.39\n354.57\n430.43\n346.40\n231.85\n...\n352.68\n428.80\n345.78\n230.81\n354.07\n428.87\n3606900\n18089100\n29290000\n53441000\n\n\n2021-07-02\n334.17\n223.11\n354.13\n420.77\n347.94\n229.19\n358.64\n433.72\n348.29\n232.08\n...\n356.28\n430.52\n347.04\n232.00\n356.52\n431.67\n3013500\n21029700\n32727200\n57697700\n\n\n2021-07-06\n332.14\n219.87\n355.66\n420.00\n345.82\n225.86\n360.19\n432.93\n348.11\n229.46\n...\n356.49\n430.01\n347.75\n229.36\n359.26\n433.78\n3910600\n27771300\n38842400\n68710400\n\n\n2021-07-07\n333.20\n217.83\n356.41\n421.49\n346.92\n223.76\n360.95\n434.46\n347.14\n226.67\n...\n358.94\n431.51\n345.65\n225.54\n362.45\n433.66\n3347000\n28521500\n35265200\n63549500\n\n\n\n\n5 rows × 24 columns\n\n\n\nThis data is not as tidy as we would like. Let’s use method chaining to perform a series of data munging operations.\n\ndf_etf = \\\n    (\n    df_etf\n        .stack() #pivot the table\n        .reset_index() #turn date into a column\n        .rename(columns={'level_1':'Symbols'}) #renaming a column\n        .sort_values(by=['Symbols', 'Date']) #sort\n        .rename(columns={'Date':'date', 'Symbols':'symbol', 'Adj Close':'adj_close','Close':'close', \n                         'High':'high', 'Low':'low', 'Open':'open', 'Volume':'volume'}) #renaming columns\n        [['date', 'symbol','open', 'high', 'low', 'close', 'volume', 'adj_close']] #reordering columns\n        .reset_index(drop=True)    \n    )\ndf_etf\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n0\n2021-06-30\nDIA\n342.38\n345.51\n342.35\n344.95\n3778900\n331.30\n\n\n1\n2021-07-01\nDIA\n345.78\n346.40\n344.92\n346.36\n3606900\n332.66\n\n\n2\n2021-07-02\nDIA\n347.04\n348.29\n346.18\n347.94\n3013500\n334.17\n\n\n3\n2021-07-06\nDIA\n347.75\n348.11\n343.60\n345.82\n3910600\n332.14\n\n\n4\n2021-07-07\nDIA\n345.65\n347.14\n344.43\n346.92\n3347000\n333.20\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n83\n2021-07-26\nSPY\n439.31\n441.03\n439.26\n441.02\n43719200\n427.85\n\n\n84\n2021-07-27\nSPY\n439.91\n439.94\n435.99\n439.01\n67397100\n425.90\n\n\n85\n2021-07-28\nSPY\n439.68\n440.30\n437.31\n438.83\n52472400\n425.73\n\n\n86\n2021-07-29\nSPY\n439.82\n441.80\n439.81\n440.65\n47435300\n427.49\n\n\n87\n2021-07-30\nSPY\n437.91\n440.06\n437.77\n438.51\n68951200\n425.42\n\n\n\n\n88 rows × 8 columns\n\n\n\n\n4.5.1 Querying for One Symbol\nWe are now ready to apply DataFrame masking to our ETF data set.\nAs a first example, let’s isolate all the rows of df_etf that correspond to IWM.\n\npd.options.display.max_rows = 6\nser_bool = (df_etf['symbol'] == \"IWM\")\ndf_etf[ser_bool]\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n22\n2021-06-30\nIWM\n228.65\n230.32\n227.76\n229.37\n26039000\n223.29\n\n\n23\n2021-07-01\nIWM\n230.81\n231.85\n229.71\n231.39\n18089100\n225.26\n\n\n24\n2021-07-02\nIWM\n232.00\n232.08\n228.56\n229.19\n21029700\n223.11\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n41\n2021-07-28\nIWM\n219.00\n222.59\n217.40\n220.82\n33043700\n214.97\n\n\n42\n2021-07-29\nIWM\n222.79\n224.44\n222.14\n222.52\n22634800\n216.62\n\n\n43\n2021-07-30\nIWM\n221.65\n224.05\n220.28\n221.05\n28473000\n215.19\n\n\n\n\n22 rows × 8 columns\n\n\n\nNotice that we did this in two steps:\n\nCalculate the series of booleans called ser_bool using comparison broadcasting.\nPerform the masking by using square brackets [] and ser_bool.\n\nWe can actually perform this masking in a single line of code, without creating the intermediate variable ser_bool.\n\ndf_etf[df_etf['symbol'] == \"IWM\"]\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n22\n2021-06-30\nIWM\n228.65\n230.32\n227.76\n229.37\n26039000\n223.29\n\n\n23\n2021-07-01\nIWM\n230.81\n231.85\n229.71\n231.39\n18089100\n225.26\n\n\n24\n2021-07-02\nIWM\n232.00\n232.08\n228.56\n229.19\n21029700\n223.11\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n41\n2021-07-28\nIWM\n219.00\n222.59\n217.40\n220.82\n33043700\n214.97\n\n\n42\n2021-07-29\nIWM\n222.79\n224.44\n222.14\n222.52\n22634800\n216.62\n\n\n43\n2021-07-30\nIWM\n221.65\n224.05\n220.28\n221.05\n28473000\n215.19\n\n\n\n\n22 rows × 8 columns\n\n\n\n\nCode Challenge: Select all the rows of df_etf for QQQ.\n\n\nSolution\ndf_etf[df_etf['symbol'] == 'QQQ']\n\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n44\n2021-06-30\nQQQ\n354.83\n355.23\n353.83\n354.43\n32724000\n349.98\n\n\n45\n2021-07-01\nQQQ\n354.07\n355.09\n352.68\n354.57\n29290000\n350.11\n\n\n46\n2021-07-02\nQQQ\n356.52\n358.97\n356.28\n358.64\n32727200\n354.13\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n63\n2021-07-28\nQQQ\n365.60\n367.45\n363.24\n365.83\n42066200\n361.23\n\n\n64\n2021-07-29\nQQQ\n365.25\n367.68\n365.25\n366.48\n25672500\n361.88\n\n\n65\n2021-07-30\nQQQ\n362.44\n365.17\n362.41\n364.57\n36484600\n359.99\n\n\n\n\n22 rows × 8 columns\n\n\n\n\n\n\n4.5.2 Querying for Multiple Symbols\nWe can use the .isin() method to query a DataFrame for multiple symbols. The technique is to feed .isin() a list of symbols you want to query for.\nThe following code grabs all the rows of df_etf for both QQQ and DIA.\n\ndf_etf[df_etf['symbol'].isin(['QQQ', 'DIA'])]\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n0\n2021-06-30\nDIA\n342.38\n345.51\n342.35\n344.95\n3778900\n331.30\n\n\n1\n2021-07-01\nDIA\n345.78\n346.40\n344.92\n346.36\n3606900\n332.66\n\n\n2\n2021-07-02\nDIA\n347.04\n348.29\n346.18\n347.94\n3013500\n334.17\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n63\n2021-07-28\nQQQ\n365.60\n367.45\n363.24\n365.83\n42066200\n361.23\n\n\n64\n2021-07-29\nQQQ\n365.25\n367.68\n365.25\n366.48\n25672500\n361.88\n\n\n65\n2021-07-30\nQQQ\n362.44\n365.17\n362.41\n364.57\n36484600\n359.99\n\n\n\n\n44 rows × 8 columns\n\n\n\n\nCode Challenge: Grab all rows of df_etf corresponding to SPY, IWM, and QQQ.\n\n\nSolution\ndf_etf[df_etf['symbol'].isin(['SPY', 'IWM', 'QQQ'])]\n\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n22\n2021-06-30\nIWM\n228.65\n230.32\n227.76\n229.37\n26039000\n223.29\n\n\n23\n2021-07-01\nIWM\n230.81\n231.85\n229.71\n231.39\n18089100\n225.26\n\n\n24\n2021-07-02\nIWM\n232.00\n232.08\n228.56\n229.19\n21029700\n223.11\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n85\n2021-07-28\nSPY\n439.68\n440.30\n437.31\n438.83\n52472400\n425.73\n\n\n86\n2021-07-29\nSPY\n439.82\n441.80\n439.81\n440.65\n47435300\n427.49\n\n\n87\n2021-07-30\nSPY\n437.91\n440.06\n437.77\n438.51\n68951200\n425.42\n\n\n\n\n66 rows × 8 columns\n\n\n\n\n\n\n4.5.3 Querying for Dates\nThe following code grabs all the rows of df_etf that come after the middle of the month.\n\ndf_etf[df_etf['date'] &gt; '2021-07-15']\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n11\n2021-07-16\nDIA\n350.72\n350.74\n346.34\n346.74\n5710400\n333.22\n\n\n12\n2021-07-19\nDIA\n341.79\n350.03\n337.38\n339.88\n9715300\n326.63\n\n\n13\n2021-07-20\nDIA\n340.29\n346.12\n339.75\n345.08\n5802200\n331.62\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n85\n2021-07-28\nSPY\n439.68\n440.30\n437.31\n438.83\n52472400\n425.73\n\n\n86\n2021-07-29\nSPY\n439.82\n441.80\n439.81\n440.65\n47435300\n427.49\n\n\n87\n2021-07-30\nSPY\n437.91\n440.06\n437.77\n438.51\n68951200\n425.42\n\n\n\n\n44 rows × 8 columns\n\n\n\n\nCode Challenge: Grab all the rows of df_etf for the last trade date of the month.\n\n\nSolution\ndf_etf[df_etf['date'] == '2021-07-30']\n\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n21\n2021-07-30\nDIA\n349.88\n351.01\n348.67\n349.48\n3576700\n335.85\n\n\n43\n2021-07-30\nIWM\n221.65\n224.05\n220.28\n221.05\n28473000\n215.19\n\n\n65\n2021-07-30\nQQQ\n362.44\n365.17\n362.41\n364.57\n36484600\n359.99\n\n\n87\n2021-07-30\nSPY\n437.91\n440.06\n437.77\n438.51\n68951200\n425.42\n\n\n\n\n\n\n\n\n\n\n4.5.4 Querying on Multiple Criteria\nWe can filter on muliple criteria by using the & operator, which is the vectorized version of and.\nSuppose that we want all rows for SPY that come before July fourth.\n\nbln_ticker = (df_etf['symbol'] == 'SPY')\nbln_date = (df_etf['date'] &lt; '2021-07-04')\nbln_combined = bln_ticker & bln_date\n\ndf_etf[bln_combined]\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n66\n2021-06-30\nSPY\n427.21\n428.78\n427.18\n428.06\n64827900\n415.28\n\n\n67\n2021-07-01\nSPY\n428.87\n430.60\n428.80\n430.43\n53441000\n417.58\n\n\n68\n2021-07-02\nSPY\n431.67\n434.10\n430.52\n433.72\n57697700\n420.77\n\n\n\n\n\n\n\n\nCode Challenge: Isolate the rows for QQQ and IWM on the last trading day before July 4th - try to not use intermediate variables.\n\ndf_etf[(df_etf['symbol'].isin([\"QQQ\", \"IWM\"])) & (df_etf['date']=='2021-07-02')]\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n24\n2021-07-02\nIWM\n232.00\n232.08\n228.56\n229.19\n21029700\n223.11\n\n\n46\n2021-07-02\nQQQ\n356.52\n358.97\n356.28\n358.64\n32727200\n354.13"
  },
  {
    "objectID": "chapters/04_query/query.html#querying-with-.query",
    "href": "chapters/04_query/query.html#querying-with-.query",
    "title": "4  DataFrame Querying",
    "section": "4.6 Querying with .query()",
    "text": "4.6 Querying with .query()\nI find querying a DataFrame via masking to be rather cumbersome.\nI greatly prefer the use of the DataFrame.query() method which uses SQL-like strings to define queries.\nFor example, the following code grabs all the rows corresponding to IWM.\n\ndf_etf.query('symbol == \"IWM\"')\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n22\n2021-06-30\nIWM\n228.65\n230.32\n227.76\n229.37\n26039000\n223.29\n\n\n23\n2021-07-01\nIWM\n230.81\n231.85\n229.71\n231.39\n18089100\n225.26\n\n\n24\n2021-07-02\nIWM\n232.00\n232.08\n228.56\n229.19\n21029700\n223.11\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n41\n2021-07-28\nIWM\n219.00\n222.59\n217.40\n220.82\n33043700\n214.97\n\n\n42\n2021-07-29\nIWM\n222.79\n224.44\n222.14\n222.52\n22634800\n216.62\n\n\n43\n2021-07-30\nIWM\n221.65\n224.05\n220.28\n221.05\n28473000\n215.19\n\n\n\n\n22 rows × 8 columns\n\n\n\nThis code queries all rows corresponding to QQQ and DIA.\n\ndf_etf.query('symbol in (\"QQQ\", \"DIA\")')\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n0\n2021-06-30\nDIA\n342.38\n345.51\n342.35\n344.95\n3778900\n331.30\n\n\n1\n2021-07-01\nDIA\n345.78\n346.40\n344.92\n346.36\n3606900\n332.66\n\n\n2\n2021-07-02\nDIA\n347.04\n348.29\n346.18\n347.94\n3013500\n334.17\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n63\n2021-07-28\nQQQ\n365.60\n367.45\n363.24\n365.83\n42066200\n361.23\n\n\n64\n2021-07-29\nQQQ\n365.25\n367.68\n365.25\n366.48\n25672500\n361.88\n\n\n65\n2021-07-30\nQQQ\n362.44\n365.17\n362.41\n364.57\n36484600\n359.99\n\n\n\n\n44 rows × 8 columns\n\n\n\nHere we grab the rows corresponding to the first half of July.\n\ndf_etf.query('date &lt; \"2021-07-15\"')\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n0\n2021-06-30\nDIA\n342.38\n345.51\n342.35\n344.95\n3778900\n331.30\n\n\n1\n2021-07-01\nDIA\n345.78\n346.40\n344.92\n346.36\n3606900\n332.66\n\n\n2\n2021-07-02\nDIA\n347.04\n348.29\n346.18\n347.94\n3013500\n334.17\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n73\n2021-07-12\nSPY\n435.43\n437.35\n434.97\n437.08\n52889600\n424.03\n\n\n74\n2021-07-13\nSPY\n436.24\n437.84\n435.31\n435.59\n52911300\n422.58\n\n\n75\n2021-07-14\nSPY\n437.40\n437.92\n434.91\n436.24\n64130400\n423.21\n\n\n\n\n40 rows × 8 columns\n\n\n\nAnd we can filter on multiple criteria via method chaining. Here we grab all the rows for SPY and IWM from the second half of the month.\n\n(\ndf_etf\n    .query('symbol in (\"SPY\", \"IWM\")')\n    .query('date &gt; \"2021-07-15\"')\n)\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n33\n2021-07-16\nIWM\n219.83\n219.88\n214.47\n214.95\n36620200\n209.25\n\n\n34\n2021-07-19\nIWM\n210.63\n214.45\n209.05\n211.73\n58571000\n206.12\n\n\n35\n2021-07-20\nIWM\n212.20\n219.27\n211.26\n218.30\n40794600\n212.51\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n85\n2021-07-28\nSPY\n439.68\n440.30\n437.31\n438.83\n52472400\n425.73\n\n\n86\n2021-07-29\nSPY\n439.82\n441.80\n439.81\n440.65\n47435300\n427.49\n\n\n87\n2021-07-30\nSPY\n437.91\n440.06\n437.77\n438.51\n68951200\n425.42\n\n\n\n\n22 rows × 8 columns\n\n\n\n\nCode Challenge: Grab all the rows of df_etf that correspond to the following criteria: 1. SPY 2. first half of month 3. close less than 435\n\n(\ndf_etf\n    .query('symbol == \"SPY\"')\n    .query('date &lt; \"2021-07-15\"')\n    .query('close &lt; 435')\n)\n\n\n\n\n\n\n\n\ndate\nsymbol\nopen\nhigh\nlow\nclose\nvolume\nadj_close\n\n\n\n\n66\n2021-06-30\nSPY\n427.21\n428.78\n427.18\n428.06\n64827900\n415.28\n\n\n67\n2021-07-01\nSPY\n428.87\n430.60\n428.80\n430.43\n53441000\n417.58\n\n\n68\n2021-07-02\nSPY\n431.67\n434.10\n430.52\n433.72\n57697700\n420.77\n\n\n69\n2021-07-06\nSPY\n433.78\n434.01\n430.01\n432.93\n68710400\n420.00\n\n\n70\n2021-07-07\nSPY\n433.66\n434.76\n431.51\n434.46\n63549500\n421.49\n\n\n71\n2021-07-08\nSPY\n428.78\n431.73\n427.52\n430.92\n97595200\n418.05"
  }
]